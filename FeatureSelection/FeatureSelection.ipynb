{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1\n",
       "5     5   116    74     0     0  25.6  0.201   30      0\n",
       "6     3    78    50    32    88  31.0  0.248   26      1\n",
       "7    10   115     0     0     0  35.3  0.134   29      0\n",
       "8     2   197    70    45   543  30.5  0.158   53      1\n",
       "9     8   125    96     0     0   0.0  0.232   54      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset: -- A classification problem\n",
    "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(\"pima-indians-diabetes.data\", names=names)\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= dataframe[['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']]\n",
    "y= dataframe['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Missing values: \n",
    "# there are zeros in places where they are biologically impossible, such as the blood pressure attribute.\n",
    "# It seems very likely that zero values encode missing data. \n",
    "# However, since the dataset donors made no such statement we encourage you to use your best judgement \n",
    "# and state your assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy values: [0.75324675324675328, 0.72727272727272729, 0.74675324675324672, 0.78431372549019607, 0.74509803921568629]\n",
      "Mean:0.75\n"
     ]
    }
   ],
   "source": [
    "# Apply NB classifier, and evaluate the model using Cross Validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "# fit the classifier on the training features and labels\n",
    "#clf.fit(X, y) \n",
    "\n",
    "scoresAcc= cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy values: \"+ str(list(scoresAcc)))\n",
    "print('Mean:%.2f' %scoresAcc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Univariate Selection: \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Statistical tests can be used to select the features that have the strongest relationship with the output variable.\n",
    "\"SelectKBest\" class in scikit-learn library can be used with a suite of different statistical tests to select a specific number of features."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For regression: f_regression, mutual_info_regression\n",
    "For classification: chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: \n",
    "## Univariate Selection: F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://en.wikipedia.org/wiki/F-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 3)\n",
      "[  5.06512730e-10   8.93543165e-43   7.15139001e-02   3.83477048e-02\n",
      "   2.86186460e-04   1.22980749e-16   1.25460701e-06   2.20997546e-11]\n",
      "[  39.67022739  213.16175218    3.2569504     4.30438091   13.28110753\n",
      "   71.7720721    23.8713002    46.14061124]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest # Select features according to the k highest scores.\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# feature extraction\n",
    "#X_new = SelectKBest(score_func=chi2, k=4).fit_transform(X, y)\n",
    "feat_selector= SelectKBest(score_func=f_classif, k=3)\n",
    "X_new= feat_selector.fit_transform(X, y)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(feat_selector.pvalues_)\n",
    "# summarize scores\n",
    "print(feat_selector.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names= X.columns.values # column names\n",
    "mask = feat_selector.get_support() #list of booleans\n",
    "new_features = [] # The list of your K best features\n",
    "\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        new_features.append(feature)\n",
    "        \n",
    "X_new= pd.DataFrame(X_new, columns= new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy values: [0.76623376623376627, 0.72727272727272729, 0.74675324675324672, 0.80392156862745101, 0.78431372549019607]\n",
      "Mean:0.77\n"
     ]
    }
   ],
   "source": [
    "# After feature selection: Apply NB classifier, and evaluate the model using Cross Validation\n",
    "clf = GaussianNB()\n",
    "\n",
    "# fit the classifier on the training features and labels\n",
    "#clf.fit(X, y) \n",
    "\n",
    "scoresAcc= cross_val_score(clf, X_new, y, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy values: \"+ str(list(scoresAcc)))\n",
    "print('Mean:%.2f' %scoresAcc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: \n",
    "## Univariate Selection: Chi-square test of independence\n",
    "\n",
    "    (http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html)\n",
    "    \n",
    "    Appropriate for only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: \n",
    "## Univariate Selection: mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(http://scikitlearn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 4)\n",
      "None\n",
      "[ 0.0313025   0.10903278  0.          0.          0.02628396  0.07192999\n",
      "  0.01164758  0.0471049 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest # Select features according to the k highest scores.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# feature extraction\n",
    "#X_new = SelectKBest(score_func=chi2, k=4).fit_transform(X, y)\n",
    "feat_selector= SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "X_new= feat_selector.fit_transform(X, y)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(feat_selector.pvalues_)\n",
    "# summarize scores\n",
    "print(feat_selector.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names= X.columns.values # column names\n",
    "mask = feat_selector.get_support() #list of booleans\n",
    "new_features = [] # The list of your K best features\n",
    "\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        new_features.append(feature)\n",
    "        \n",
    "X_new= pd.DataFrame(X_new, columns= new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy values: [0.75974025974025972, 0.69480519480519476, 0.75324675324675328, 0.77124183006535951, 0.77777777777777779]\n",
      "Mean:0.75\n"
     ]
    }
   ],
   "source": [
    "# After feature selection: Apply NB classifier, and evaluate the model using Cross Validation\n",
    "clf = GaussianNB()\n",
    "\n",
    "# fit the classifier on the training features and labels\n",
    "#clf.fit(X, y) \n",
    "\n",
    "scoresAcc= cross_val_score(clf, X_new, y, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy values: \"+ str(list(scoresAcc)))\n",
    "print('Mean:%.2f' %scoresAcc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Removing features with low variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# VarianceThreshold removes all features whose variance doesnâ€™t meet some threshold. \n",
    "# By default, it removes all zero-variance features, i.e. features that have the same value in all samples.\n",
    "\n",
    "feat_selector= VarianceThreshold()\n",
    "\n",
    "X_new= feat_selector.fit_transform(X, y)\n",
    "\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# VarianceThreshold makes more sense for binary features: \n",
    "\n",
    "As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Boolean features are Bernoulli random variables, and the variance of such variables is given by\n",
    "Var(x) = p(1 - p)\n",
    "so we can select using the threshold = .8 * (1 - .8)\n",
    "\n",
    "Then, VarianceThreshold will remove the columns, which have a probability of having the same values greater thyan this threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Recursive feature elimination: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature selection using SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
